{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMncNmibB7Zo9mClhHiprRb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/axxbit/Machine-Learning-ID3/blob/main/backup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYkrFGXVLDBB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, label=None, attribute=None):\n",
        "        self.label = label  # The class label (1 or 0)\n",
        "        self.attribute = attribute  # The attribute to split on\n",
        "        self.children = {}  # Dictionary to store child nodes\n",
        "\n",
        "def entropy(data):\n",
        "    # Calculate the entropy of a dataset\n",
        "    if len(data) == 0:\n",
        "        return 0\n",
        "    p = data.mean()\n",
        "    if p == 0 or p == 1:\n",
        "        return 0\n",
        "    return -p * np.log2(p) - (1 - p) * np.log2(1 - p)\n",
        "\n",
        "def information_gain(data, attribute_name, target_name):\n",
        "    # Calculate the information gain of an attribute\n",
        "    entropy_before = entropy(data[target_name])\n",
        "    values = data[attribute_name].unique()\n",
        "    entropy_after = 0\n",
        "    for value in values:\n",
        "        subset = data[data[attribute_name] == value]\n",
        "        entropy_after += len(subset) / len(data) * entropy(subset[target_name])\n",
        "    return entropy_before - entropy_after\n",
        "\n",
        "def id3(data, target_name, attribute_names):\n",
        "    # Base cases\n",
        "    if len(data) == 0:\n",
        "        return Node()\n",
        "    if len(data[target_name].unique()) == 1:\n",
        "        return Node(data[target_name].iloc[0])\n",
        "    if len(attribute_names) == 0:\n",
        "        return Node(data[target_name].mode().iloc[0])\n",
        "\n",
        "    # Select the best attribute to split on\n",
        "    information_gains = {attr: information_gain(data, attr, target_name) for attr in attribute_names}\n",
        "    best_attribute = max(information_gains, key=information_gains.get)\n",
        "\n",
        "    # Create a new decision tree node\n",
        "    tree = Node()\n",
        "    tree.attribute = best_attribute\n",
        "\n",
        "    # Recursively build the tree for each value of the best attribute\n",
        "    for value in data[best_attribute].unique():\n",
        "        subset = data[data[best_attribute] == value]\n",
        "        subtree = id3(subset, target_name, [attr for attr in attribute_names if attr != best_attribute])\n",
        "        tree.children[value] = subtree\n",
        "\n",
        "    return tree\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset from a CSV file\n",
        "dataset = pd.read_csv(\"lol.csv\")\n",
        "\n",
        "# Remove the \"gameId\" column\n",
        "dataset = dataset.drop(\"gameId\", axis=1)\n",
        "\n",
        "# Define the target variable and attribute names\n",
        "target_variable = \"blueWins\"\n",
        "attribute_names = dataset.columns.drop(target_variable)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and testing sets (e.g., 80% training, 20% testing)\n",
        "train_data, test_and_validation_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "validation_data, test_data = train_test_split(test_and_validation_data, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "wY0-f5iuB7PN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the ID3 decision tree\n",
        "decision_tree = id3(train_data, target_variable, attribute_names)"
      ],
      "metadata": {
        "id": "4uRBJNl3CAtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def id3_with_max_depth(data, target_name, attribute_names, max_depth=None, current_depth=0):\n",
        "    # Base cases\n",
        "    if len(data) == 0:\n",
        "        return Node()\n",
        "    if len(data[target_name].unique()) == 1:\n",
        "        return Node(data[target_name].iloc[0])\n",
        "    if len(attribute_names) == 0 or (max_depth is not None and current_depth >= max_depth):\n",
        "        return Node(data[target_name].mode().iloc[0])\n",
        "\n",
        "    # Select the best attribute to split on\n",
        "    information_gains = {attr: information_gain(data, attr, target_name) for attr in attribute_names}\n",
        "    best_attribute = max(information_gains, key=information_gains.get)\n",
        "\n",
        "    # Create a new decision tree node\n",
        "    tree = Node()\n",
        "    tree.attribute = best_attribute\n",
        "\n",
        "    # Recursively build the tree for each value of the best attribute\n",
        "    for value in data[best_attribute].unique():\n",
        "        subset = data[data[best_attribute] == value]\n",
        "        subtree = id3_with_max_depth(subset, target_name, [attr for attr in attribute_names if attr != best_attribute], max_depth, current_depth + 1)\n",
        "        tree.children[value] = subtree\n",
        "\n",
        "    return tree\n",
        "\n",
        "max_depth = 4  # Set your desired maximum depth\n",
        "max_depth_tree = id3_with_max_depth(train_data, target_variable, attribute_names, max_depth)"
      ],
      "metadata": {
        "id": "YdgiKNIhCR-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_tree(tree, validation_data, target_variable):\n",
        "    # Base case: If the tree is a leaf node, return the tree\n",
        "    if tree.label is not None:\n",
        "        return tree\n",
        "\n",
        "    # Recursively prune the subtrees\n",
        "    for value in tree.children:\n",
        "        subtree = tree.children[value]\n",
        "        tree.children[value] = prune_tree(subtree, validation_data, target_variable)\n",
        "\n",
        "    # Calculate the accuracy of the unpruned tree on the validation data\n",
        "    original_accuracy = accuracy_score(predict_labels(tree, validation_data), validation_data[target_variable])\n",
        "\n",
        "    # Temporarily prune the current subtree by turning it into a leaf node\n",
        "    original_children = tree.children\n",
        "    tree.children = {}\n",
        "    tree.label = validation_data[target_variable].mode().iloc[0]\n",
        "\n",
        "    # Calculate the accuracy of the pruned tree on the validation data\n",
        "    pruned_accuracy = accuracy_score(predict_labels(tree, validation_data), validation_data[target_variable])\n",
        "\n",
        "    # If pruning doesn't decrease accuracy, keep the tree pruned; otherwise, revert to the original\n",
        "    if pruned_accuracy >= original_accuracy:\n",
        "        return tree\n",
        "    else:\n",
        "        tree.children = original_children\n",
        "        tree.label = None\n",
        "        return tree"
      ],
      "metadata": {
        "id": "6PSUDPD8GpNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now you can use the decision tree to make predictions\n",
        "# For example, you can traverse the tree to predict a new data point\n",
        "def predict(tree, data_point):\n",
        "    if tree.label is not None:\n",
        "        return tree.label\n",
        "\n",
        "    attribute_value = data_point.get(tree.attribute)\n",
        "    if attribute_value is None:\n",
        "        # Return an error message as a string\n",
        "        return \"Error: Attribute '{}' not found in the data_point\".format(tree.attribute)\n",
        "\n",
        "    if attribute_value not in tree.children:\n",
        "        return dataset[target_variable].mode().iloc[0]\n",
        "\n",
        "    return predict(tree.children[attribute_value], data_point)\n",
        "\n",
        "# Example prediction for a new data point (replace with actual data)\n",
        "new_data_point = {\"blueWardsPlaced\": 2, \"blueWardsDestroyed\": 1, \"blueFirstBlood\": 1, \"blueGoldDiff\": 2000}\n",
        "prediction = predict(decision_tree, new_data_point)\n",
        "print(\"Predicted blueWins:\", prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCg2bMPXCCO9",
        "outputId": "b6e93e0c-cc9b-4bcc-ec6a-1c02bb8870e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted blueWins: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Predict the target values on the test data\n",
        "def predict_labels(tree, test_data):\n",
        "    predicted_labels = [predict(tree, data_point) for _, data_point in test_data.iterrows()]\n",
        "    return predicted_labels\n",
        "\n",
        "predicted_labels = predict_labels(decision_tree, test_data)\n",
        "\n",
        "# Get the true labels from the test data\n",
        "true_labels = test_data[target_variable]\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(true_labels, predicted_labels)\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# Create a confusion matrix\n",
        "confusion = confusion_matrix(true_labels, predicted_labels)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sMOIWRqCH52",
        "outputId": "58863744-e670-4e69-850f-1136be297c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5738866396761133\n",
            "Precision: 0.5890804597701149\n",
            "Recall: 0.4244306418219462\n",
            "F1 Score: 0.49338146811070993\n",
            "Confusion Matrix:\n",
            "[[362 143]\n",
            " [278 205]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create pruned tree\n",
        "\n",
        "pruned_tree = prune_tree(decision_tree, validation_data, target_variable)\n",
        "\n",
        "# Example prediction for a new data point using the pruned tree (replace with actual data)\n",
        "new_data_point = {\"blueWardsPlaced\": 2, \"blueWardsDestroyed\": 1, \"blueFirstBlood\": 1, \"blueGoldDiff\": 2000}\n",
        "prediction = predict(pruned_tree, new_data_point)\n",
        "print(\"Predicted blueWins with pruned tree:\", prediction)\n",
        "\n",
        "# Example of evaluating the pruned tree\n",
        "pruned_predicted_labels = predict_labels(pruned_tree, test_data)\n",
        "pruned_accuracy = accuracy_score(true_labels, pruned_predicted_labels)\n",
        "print(\"Accuracy with pruned tree:\", pruned_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVqmSBuoMi22",
        "outputId": "32f18317-b379-49b0-c509-0e7ca14ecb51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted blueWins with pruned tree: 1\n",
            "Accuracy with pruned tree: 0.5738866396761133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Predict the target values on the test data using the pruned tree\n",
        "pruned_predicted_labels = predict_labels(pruned_tree, test_data)\n",
        "\n",
        "# Get the true labels from the test data\n",
        "true_labels = test_data[target_variable]\n",
        "\n",
        "# Calculate accuracy with the pruned tree\n",
        "accuracy = accuracy_score(true_labels, pruned_predicted_labels)\n",
        "print(\"Accuracy with pruned tree:\", accuracy)\n",
        "\n",
        "# Calculate precision with the pruned tree\n",
        "precision = precision_score(true_labels, pruned_predicted_labels)\n",
        "print(\"Precision with pruned tree:\", precision)\n",
        "\n",
        "# Calculate recall with the pruned tree\n",
        "recall = recall_score(true_labels, pruned_predicted_labels)\n",
        "print(\"Recall with pruned tree:\", recall)\n",
        "\n",
        "# Calculate F1 score with the pruned tree\n",
        "f1 = f1_score(true_labels, pruned_predicted_labels)\n",
        "print(\"F1 Score with pruned tree:\", f1)\n",
        "\n",
        "# Create a confusion matrix with the pruned tree\n",
        "confusion = confusion_matrix(true_labels, pruned_predicted_labels)\n",
        "print(\"Confusion Matrix with pruned tree:\")\n",
        "print(confusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkc7m1DSPGHH",
        "outputId": "96bb8eb7-cc59-47cf-ba57-50fe21448666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with pruned tree: 0.5738866396761133\n",
            "Precision with pruned tree: 0.5890804597701149\n",
            "Recall with pruned tree: 0.4244306418219462\n",
            "F1 Score with pruned tree: 0.49338146811070993\n",
            "Confusion Matrix with pruned tree:\n",
            "[[362 143]\n",
            " [278 205]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the target values on the test data using the max_depth_tree (unpruned tree)\n",
        "max_depth_predicted_labels = predict_labels(max_depth_tree, test_data)\n",
        "\n",
        "# Get the true labels from the test data\n",
        "true_labels = test_data[target_variable]\n",
        "\n",
        "# Calculate accuracy with the max_depth_tree (unpruned tree)\n",
        "accuracy = accuracy_score(true_labels, max_depth_predicted_labels)\n",
        "print(\"Accuracy with max_depth_tree (unpruned tree):\", accuracy)\n",
        "\n",
        "# Calculate precision with the max_depth_tree (unpruned tree)\n",
        "precision = precision_score(true_labels, max_depth_predicted_labels)\n",
        "print(\"Precision with max_depth_tree (unpruned tree):\", precision)\n",
        "\n",
        "# Calculate recall with the max_depth_tree (unpruned tree)\n",
        "recall = recall_score(true_labels, max_depth_predicted_labels)\n",
        "print(\"Recall with max_depth_tree (unpruned tree):\", recall)\n",
        "\n",
        "# Calculate F1 score with the max_depth_tree (unpruned tree)\n",
        "f1 = f1_score(true_labels, max_depth_predicted_labels)\n",
        "print(\"F1 Score with max_depth_tree (unpruned tree):\", f1)\n",
        "\n",
        "# Create a confusion matrix with the max_depth_tree (unpruned tree)\n",
        "confusion = confusion_matrix(true_labels, max_depth_predicted_labels)\n",
        "print(\"Confusion Matrix with max_depth_tree (unpruned tree):\")\n",
        "print(confusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HetkAbibQLt3",
        "outputId": "5edce0bf-1c40-4081-9804-e5a74a484772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with max_depth_tree (unpruned tree): 0.5809716599190283\n",
            "Precision with max_depth_tree (unpruned tree): 0.6589861751152074\n",
            "Recall with max_depth_tree (unpruned tree): 0.29606625258799174\n",
            "F1 Score with max_depth_tree (unpruned tree): 0.40857142857142864\n",
            "Confusion Matrix with max_depth_tree (unpruned tree):\n",
            "[[431  74]\n",
            " [340 143]]\n"
          ]
        }
      ]
    }
  ]
}